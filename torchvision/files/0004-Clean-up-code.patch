From 8027371766c60dfd42ce88630bbdb405835d00ea Mon Sep 17 00:00:00 2001
From: t-kuha <imagingtechnerd@gmail.com>
Date: Wed, 23 Feb 2022 20:30:02 +0900
Subject: [PATCH 4/4] Clean-up code

---
 setup.py | 396 ++++---------------------------------------------------
 1 file changed, 29 insertions(+), 367 deletions(-)

diff --git a/setup.py b/setup.py
index bc0990456..6cc780bb0 100644
--- a/setup.py
+++ b/setup.py
@@ -3,15 +3,17 @@ import io
 import re
 import sys
 from setuptools import setup, find_packages, Extension
-from pkg_resources import parse_version, get_distribution, DistributionNotFound
+from setuptools.command.build_ext import build_ext
+from pkg_resources import get_distribution, DistributionNotFound
 import subprocess
 import distutils.command.clean
 import distutils.spawn
-from distutils.version import StrictVersion
 import glob
 import shutil
-
-# from torch.utils.cpp_extension import BuildExtension
+from typing import List
+import copy
+import shlex
+import warnings
 
 
 def read(*names, **kwargs):
@@ -77,6 +79,7 @@ _TORCH_PATH = os.path.join(
     os.environ.get('PKG_CONFIG_SYSROOT_DIR', None),
     'usr', 'lib', f'python{sys.version_info.major}.{sys.version_info.minor}', 'site-packages', 'torch')
 
+
 def include_paths(cuda=False):
     lib_include = os.path.join(_TORCH_PATH, 'include')
     paths = [
@@ -101,7 +104,6 @@ def CppExtension(name, sources, *args, **kwargs):
 
     library_dirs = kwargs.get('library_dirs', [])
     library_dirs += library_paths()
-    # print(f'*** {library_dirs}')
     kwargs['library_dirs'] = library_dirs
 
     libraries = kwargs.get('libraries', [])
@@ -187,8 +189,6 @@ def get_extensions():
         glob.glob(os.path.join(extensions_dir, 'ops', 'quantized', 'cpu', '*.cpp'))
     )
 
-    is_rocm_pytorch = False
-
     sources = main_file + source_cpu
     extension = CppExtension
 
@@ -266,8 +266,8 @@ def get_extensions():
 
     # Locating libPNG
     png_found = True  # libpng is not None or pngfix is not None
-    png_include = os.path.join(os.environ['PKG_CONFIG_SYSROOT_DIR'], 'usr', 'include')
-    png_lib = os.path.join(os.environ['PKG_CONFIG_SYSROOT_DIR'], 'usr', 'lib')
+    # png_include = os.path.join(os.environ['PKG_CONFIG_SYSROOT_DIR'], 'usr', 'include')
+    # png_lib = os.path.join(os.environ['PKG_CONFIG_SYSROOT_DIR'], 'usr', 'lib')
     print('PNG found: {0}'.format(png_found))
     image_link_flags.append('png')
 
@@ -302,9 +302,6 @@ def get_extensions():
     image_src = (glob.glob(os.path.join(image_path, '*.cpp')) + glob.glob(os.path.join(image_path, 'cpu', '*.cpp'))
                  + glob.glob(os.path.join(image_path, 'cuda', '*.cpp')))
 
-    # print(f'{image_library=:}')
-    # print(f'{library_dirs=:}')
-    # print(f'{image_link_flags=:}')
     if png_found or jpeg_found:
         ext_modules.append(extension(
             'torchvision.image',
@@ -403,13 +400,11 @@ class clean(distutils.command.clean.clean):
         # It's an old-style class in Python 2.7...
         distutils.command.clean.clean.run(self)
 
-# -----------------------------------------------------------------------------
+
 SUBPROCESS_DECODE_ARGS = ()
 MINIMUM_GCC_VERSION = (5, 0, 0)
-from typing import List
-import copy
-import shlex
-import warnings
+
+
 def is_ninja_available():
     try:
         subprocess.check_output('ninja --version'.split())
@@ -418,6 +413,7 @@ def is_ninja_available():
     else:
         return True
 
+
 def _get_num_workers(verbose: bool):
     max_jobs = os.environ.get('MAX_JOBS')
     if max_jobs is not None and max_jobs.isdigit():
@@ -429,20 +425,17 @@ def _get_num_workers(verbose: bool):
               '(overridable by setting the environment variable MAX_JOBS=N)')
     return None
 
+
 def _is_cuda_file(path: str) -> bool:
     valid_ext = ['.cu', '.cuh']
-    # if IS_HIP_EXTENSION:
-    #     valid_ext.append('.hip')
     return os.path.splitext(path)[1] in valid_ext
 
+
 def verify_ninja_availability():
-    r'''
-    Raises ``RuntimeError`` if `ninja <https://ninja-build.org/>`_ build system is not
-    available on the system, does nothing otherwise.
-    '''
     if not is_ninja_available():
         raise RuntimeError("Ninja is required to load C++ extensions")
 
+
 def _write_ninja_file(path,
                       cflags,
                       post_cflags,
@@ -453,19 +446,6 @@ def _write_ninja_file(path,
                       ldflags,
                       library_target,
                       with_cuda) -> None:
-    r"""Write a ninja file that does the desired compiling and linking.
-    `path`: Where to write this file
-    `cflags`: list of flags to pass to $cxx. Can be None.
-    `post_cflags`: list of flags to append to the $cxx invocation. Can be None.
-    `cuda_cflags`: list of flags to pass to $nvcc. Can be None.
-    `cuda_postflags`: list of flags to append to the $nvcc invocation. Can be None.
-    `sources`: list of paths to source files
-    `objects`: list of desired paths to objects, one per source.
-    `ldflags`: list of flags to pass to linker. Can be None.
-    `library_target`: Name of the output library. Can be None; in that case,
-                      we do no linking.
-    `with_cuda`: If we should be compiling with CUDA.
-    """
     def sanitize_flags(flags):
         if flags is None:
             return []
@@ -482,25 +462,15 @@ def _write_ninja_file(path,
     assert len(sources) == len(objects)
     assert len(sources) > 0
 
-    # if IS_WINDOWS:
-    #     compiler = os.environ.get('CXX', 'cl')
-    # else:
     compiler = os.environ.get('CXX', 'c++')
 
     # Version 1.3 is required for the `deps` directive.
     config = ['ninja_required_version = 1.3']
     config.append(f'cxx = {compiler}')
-    if with_cuda:
-        nvcc = _join_cuda_home('bin', 'nvcc')
-        config.append(f'nvcc = {nvcc}')
 
     flags = [f'cflags = {" ".join(cflags)}']
     flags.append(f'post_cflags = {" ".join(post_cflags)}')
-    if with_cuda:
-        flags.append(f'cuda_cflags = {" ".join(cuda_cflags)}')
-        flags.append(f'cuda_post_cflags = {" ".join(cuda_post_cflags)}')
     flags.append(f'ldflags = {" ".join(ldflags)}')
-    print(f'{ldflags=:}')
 
     # Turn into absolute paths so we can emit them into the ninja build
     # file wherever it is.
@@ -508,58 +478,22 @@ def _write_ninja_file(path,
 
     # See https://ninja-build.org/build.ninja.html for reference.
     compile_rule = ['rule compile']
-    # if IS_WINDOWS:
-    #     compile_rule.append(
-    #         '  command = cl /showIncludes $cflags -c $in /Fo$out $post_cflags')
-    #     compile_rule.append('  deps = msvc')
-    # else:
     compile_rule.append(
         '  command = $cxx -MMD -MF $out.d $cflags -c $in -o $out $post_cflags')
     compile_rule.append('  depfile = $out.d')
     compile_rule.append('  deps = gcc')
 
-    if with_cuda:
-        cuda_compile_rule = ['rule cuda_compile']
-        nvcc_gendeps = ''
-        # --generate-dependencies-with-compile was added in CUDA 10.2.
-        # Compilation will work on earlier CUDA versions but header file
-        # dependencies are not correctly computed.
-        required_cuda_version = packaging.version.parse('10.2')
-        has_cuda_version = torch.version.cuda is not None
-        if has_cuda_version and packaging.version.parse(torch.version.cuda) >= required_cuda_version:
-            cuda_compile_rule.append('  depfile = $out.d')
-            cuda_compile_rule.append('  deps = gcc')
-            # Note: non-system deps with nvcc are only supported
-            # on Linux so use --generate-dependencies-with-compile
-            # to make this work on Windows too.
-            # if IS_WINDOWS:
-            #     nvcc_gendeps = '--generate-dependencies-with-compile --dependency-output $out.d'
-        cuda_compile_rule.append(
-            f'  command = $nvcc {nvcc_gendeps} $cuda_cflags -c $in -o $out $cuda_post_cflags')
-
     # Emit one build rule per source to enable incremental build.
     build = []
     for source_file, object_file in zip(sources, objects):
         is_cuda_source = _is_cuda_file(source_file) and with_cuda
         rule = 'cuda_compile' if is_cuda_source else 'compile'
-        # if IS_WINDOWS:
-        #     source_file = source_file.replace(':', '$:')
-        #     object_file = object_file.replace(':', '$:')
         source_file = source_file.replace(" ", "$ ")
         object_file = object_file.replace(" ", "$ ")
         build.append(f'build {object_file}: {rule} {source_file}')
 
     if library_target is not None:
         link_rule = ['rule link']
-        # if IS_WINDOWS:
-        #     cl_paths = subprocess.check_output(['where',
-        #                                         'cl']).decode(*SUBPROCESS_DECODE_ARGS).split('\r\n')
-        #     if len(cl_paths) >= 1:
-        #         cl_path = os.path.dirname(cl_paths[0]).replace(':', '$:')
-        #     else:
-        #         raise RuntimeError("MSVC is required to load C++ extensions")
-        #     link_rule.append(f'  command = "{cl_path}/link.exe" $in /nologo $ldflags /out:$out')
-        # else:
         link_rule.append('  command = $cxx $in $ldflags -o $out')
 
         link = [f'build {library_target}: link {" ".join(objects)}']
@@ -570,14 +504,13 @@ def _write_ninja_file(path,
 
     # 'Blocks' should be separated by newlines, for visual benefit.
     blocks = [config, flags, compile_rule]
-    if with_cuda:
-        blocks.append(cuda_compile_rule)
     blocks += [link_rule, build, link, default]
     with open(path, 'w') as build_file:
         for block in blocks:
             lines = '\n'.join(block)
             build_file.write(f'{lines}\n\n')
 
+
 def _write_ninja_file_and_compile_objects(
         sources: List[str],
         objects,
@@ -589,9 +522,6 @@ def _write_ninja_file_and_compile_objects(
         verbose: bool,
         with_cuda) -> None:
     verify_ninja_availability()
-    # if IS_WINDOWS:
-    #     compiler = os.environ.get('CXX', 'cl')
-    # else:
     compiler = os.environ.get('CXX', 'c++')
     check_compiler_abi_compatibility(compiler)
     if with_cuda is None:
@@ -619,41 +549,16 @@ def _write_ninja_file_and_compile_objects(
         # that failed to build but there isn't a good way to get it here.
         error_prefix='Error compiling objects for extension')
 
+
 def _run_ninja_build(build_directory: str, verbose: bool, error_prefix: str) -> None:
     command = ['ninja', '-v']
     num_workers = _get_num_workers(verbose)
     if num_workers is not None:
         command.extend(['-j', str(num_workers)])
     env = os.environ.copy()
-    # Try to activate the vc env for the users
-    # if IS_WINDOWS and 'VSCMD_ARG_TGT_ARCH' not in env:
-    #     from setuptools import distutils
-
-    #     plat_name = distutils.util.get_platform()
-    #     plat_spec = PLAT_TO_VCVARS[plat_name]
-
-    #     vc_env = distutils._msvccompiler._get_vc_env(plat_spec)
-    #     vc_env = {k.upper(): v for k, v in vc_env.items()}
-    #     for k, v in env.items():
-    #         uk = k.upper()
-    #         if uk not in vc_env:
-    #             vc_env[uk] = v
-    #     env = vc_env
     try:
         sys.stdout.flush()
         sys.stderr.flush()
-        # Warning: don't pass stdout=None to subprocess.run to get output.
-        # subprocess.run assumes that sys.__stdout__ has not been modified and
-        # attempts to write to it by default.  However, when we call _run_ninja_build
-        # from ahead-of-time cpp extensions, the following happens:
-        # 1) If the stdout encoding is not utf-8, setuptools detachs __stdout__.
-        #    https://github.com/pypa/setuptools/blob/7e97def47723303fafabe48b22168bbc11bb4821/setuptools/dist.py#L1110
-        #    (it probably shouldn't do this)
-        # 2) subprocess.run (on POSIX, with no stdout override) relies on
-        #    __stdout__ not being detached:
-        #    https://github.com/python/cpython/blob/c352e6c7446c894b13643f538db312092b351789/Lib/subprocess.py#L1214
-        # To work around this, we pass in the fileno directly and hope that
-        # it is valid.
         stdout_fileno = 1
         subprocess.run(
             command,
@@ -673,22 +578,19 @@ def _run_ninja_build(build_directory: str, verbose: bool, error_prefix: str) ->
             message += f": {error.output.decode(*SUBPROCESS_DECODE_ARGS)}"  # type: ignore[union-attr]
         raise RuntimeError(message) from e
 
+
 def _accepted_compilers_for_platform() -> List[str]:
     # gnu-c++ and gnu-cc are the conda gcc compilers
     return ['clang++', 'clang'] if sys.platform.startswith('darwin') else ['g++', 'gcc', 'gnu-c++', 'gnu-cc']
 
+
 def check_compiler_abi_compatibility(compiler) -> bool:
-    # if not _is_binary_build():
-    #     return True
     if os.environ.get('TORCH_DONT_CHECK_COMPILER_ABI') in ['ON', '1', 'YES', 'TRUE', 'Y']:
         return True
 
     # First check if the compiler is one of the expected ones for the particular platform.
     if not check_compiler_ok_for_platform(compiler):
-        warnings.warn(WRONG_COMPILER_WARNING.format(
-            user_compiler=compiler,
-            pytorch_compiler=_accepted_compilers_for_platform()[0],
-            platform=sys.platform))
+        warnings.warn(f'Your compiler ({compiler}) is not compatible with the compiler Pytorch was built with for this platform')
         return False
 
     if sys.platform.startswith('darwin'):
@@ -699,11 +601,6 @@ def check_compiler_abi_compatibility(compiler) -> bool:
             minimum_required_version = MINIMUM_GCC_VERSION
             versionstr = subprocess.check_output([compiler.split(' ')[0], '-dumpfullversion', '-dumpversion'])
             version = versionstr.decode(*SUBPROCESS_DECODE_ARGS).strip().split('.')
-        else:
-            minimum_required_version = MINIMUM_MSVC_VERSION
-            compiler_info = subprocess.check_output(compiler, stderr=subprocess.STDOUT)
-            match = re.search(r'(\d+)\.(\d+)\.(\d+)', compiler_info.decode(*SUBPROCESS_DECODE_ARGS).strip())
-            version = (0, 0, 0) if match is None else match.groups()
     except Exception:
         _, error, _ = sys.exc_info()
         warnings.warn(f'Error checking compiler version for {compiler}: {error}')
@@ -713,10 +610,11 @@ def check_compiler_abi_compatibility(compiler) -> bool:
         return True
 
     compiler = f'{compiler} {".".join(version)}'
-    warnings.warn(ABI_INCOMPATIBILITY_WARNING.format(compiler))
+    warnings.warn(f'Your compiler ({compiler}) may be ABI-incompatible with PyTorch!')
 
     return False
 
+
 def check_compiler_ok_for_platform(compiler: str) -> bool:
     which = subprocess.check_output(['which', compiler.split(' ')[0]], stderr=subprocess.STDOUT)
     # Use os.path.realpath to resolve any symlinks, in particular from 'c++' to e.g. 'g++'.
@@ -739,7 +637,7 @@ def check_compiler_ok_for_platform(compiler: str) -> bool:
         return version_string.startswith("Apple clang")
     return False
 
-from setuptools.command.build_ext import build_ext
+
 class BuildExtension(build_ext, object):
     @classmethod
     def with_options(cls, **options):
@@ -759,7 +657,6 @@ class BuildExtension(build_ext, object):
         self.no_python_abi_suffix = kwargs.get("no_python_abi_suffix", False)
 
         self.use_ninja = kwargs.get('use_ninja', True)
-        print(self.use_ninja)
         if self.use_ninja:
             # Test if we can use ninja. Fallback otherwise.
             msg = ('Attempted to use ninja as the BuildExtension backend but '
@@ -788,13 +685,6 @@ class BuildExtension(build_ext, object):
             extension = next(extension_iter, None)
 
         for extension in self.extensions:
-            # Ensure at least an empty list of flags for 'cxx' and 'nvcc' when
-            # extra_compile_args is a dict. Otherwise, default torch flags do
-            # not get passed. Necessary when only one of 'cxx' and 'nvcc' is
-            # passed to extra_compile_args in CUDAExtension, i.e.
-            #   CUDAExtension(..., extra_compile_args={'cxx': [...]})
-            # or
-            #   CUDAExtension(..., extra_compile_args={'nvcc': [...]})
             if isinstance(extension.extra_compile_args, dict):
                 for ext in ['cxx', 'nvcc']:
                     if ext not in extension.extra_compile_args:
@@ -803,8 +693,6 @@ class BuildExtension(build_ext, object):
             self._add_compile_flag(extension, '-DTORCH_API_INCLUDE_EXTENSION_H')
             # See note [Pybind11 ABI constants]
             for name, val in {"COMPILER_TYPE": '_gcc', "STDLIB": '_libstdcpp', "BUILD_ABI": '_cxxabi1014'}.items():
-                # val = getattr(torch._C, f"_PYBIND11_{name}")
-                # if val is not None:
                 self._add_compile_flag(extension, f'-DPYBIND11_{name}="{val}"')
             self._define_torch_extension_name(extension)
             self._add_gnu_cpp_abi_flag(extension)
@@ -815,7 +703,6 @@ class BuildExtension(build_ext, object):
         if self.compiler.compiler_type == 'msvc':
             self.compiler._cpp_extensions += ['.cu', '.cuh']
             original_compile = self.compiler.compile
-            original_spawn = self.compiler.spawn
         else:
             original_compile = self.compiler._compile
 
@@ -828,22 +715,6 @@ class BuildExtension(build_ext, object):
             if not any(flag.startswith(cpp_flag_prefix) for flag in cflags):
                 cflags.append(cpp_flag)
 
-        def unix_cuda_flags(cflags):
-            cflags = (COMMON_NVCC_FLAGS +
-                      ['--compiler-options', "'-fPIC'"] +
-                      cflags + _get_cuda_arch_flags(cflags))
-
-            # NVCC does not allow multiple -ccbin/--compiler-bindir to be passed, so we avoid
-            # overriding the option if the user explicitly passed it.
-            _ccbin = os.getenv("CC")
-            if (
-                _ccbin is not None
-                and not any([flag.startswith('-ccbin') or flag.startswith('--compiler-bindir') for flag in cflags])
-            ):
-                cflags.extend(['-ccbin', _ccbin])
-
-            return cflags
-
         def convert_to_absolute_paths_inplace(paths):
             # Helper function. See Note [Absolute include_dirs]
             if paths is not None:
@@ -857,12 +728,7 @@ class BuildExtension(build_ext, object):
             try:
                 original_compiler = self.compiler.compiler_so
                 if _is_cuda_file(src):
-                    nvcc = [_join_cuda_home('bin', 'nvcc')]
-                    self.compiler.set_executable('compiler_so', nvcc)
-                    if isinstance(cflags, dict):
-                        cflags = cflags['nvcc']
-                    else:
-                        cflags = unix_cuda_flags(cflags)
+                    pass
                 elif isinstance(cflags, dict):
                     cflags = cflags['cxx']
                 append_std14_if_no_std_present(cflags)
@@ -880,18 +746,6 @@ class BuildExtension(build_ext, object):
                                     extra_preargs=None,
                                     extra_postargs=None,
                                     depends=None):
-            r"""Compiles sources by outputting a ninja file and running it."""
-            # NB: I copied some lines from self.compiler (which is an instance
-            # of distutils.UnixCCompiler). See the following link.
-            # https://github.com/python/cpython/blob/f03a8f8d5001963ad5b5b28dbd95497e9cc15596/Lib/distutils/ccompiler.py#L564-L567
-            # This can be fragile, but a lot of other repos also do this
-            # (see https://github.com/search?q=_setup_compile&type=Code)
-            # so it is probably OK; we'll also get CI signal if/when
-            # we update our python version (which is when distutils can be
-            # upgraded)
-
-            # Use absolute path for output_dir so that the object file paths
-            # (`objects`) get generated with absolute paths.
             output_dir = os.path.abspath(output_dir)
 
             # See Note [Absolute include_dirs]
@@ -918,17 +772,6 @@ class BuildExtension(build_ext, object):
 
             cuda_post_cflags = None
             cuda_cflags = None
-            if with_cuda:
-                cuda_cflags = common_cflags
-                if isinstance(extra_postargs, dict):
-                    cuda_post_cflags = extra_postargs['nvcc']
-                else:
-                    cuda_post_cflags = list(extra_postargs)
-
-                cuda_post_cflags = unix_cuda_flags(cuda_post_cflags)
-                append_std14_if_no_std_present(cuda_post_cflags)
-                cuda_cflags = [shlex.quote(f) for f in cuda_cflags]
-                cuda_post_cflags = [shlex.quote(f) for f in cuda_post_cflags]
 
             _write_ninja_file_and_compile_objects(
                 sources=sources,
@@ -944,170 +787,13 @@ class BuildExtension(build_ext, object):
             # Return *all* object filenames, not just the ones we just built.
             return objects
 
-        def win_cuda_flags(cflags):
-            return (COMMON_NVCC_FLAGS +
-                    cflags + _get_cuda_arch_flags(cflags))
-
-        def win_wrap_single_compile(sources,
-                                    output_dir=None,
-                                    macros=None,
-                                    include_dirs=None,
-                                    debug=0,
-                                    extra_preargs=None,
-                                    extra_postargs=None,
-                                    depends=None):
-
-            self.cflags = copy.deepcopy(extra_postargs)
-            extra_postargs = None
-
-            def spawn(cmd):
-                # Using regex to match src, obj and include files
-                src_regex = re.compile('/T(p|c)(.*)')
-                src_list = [
-                    m.group(2) for m in (src_regex.match(elem) for elem in cmd)
-                    if m
-                ]
-
-                obj_regex = re.compile('/Fo(.*)')
-                obj_list = [
-                    m.group(1) for m in (obj_regex.match(elem) for elem in cmd)
-                    if m
-                ]
-
-                include_regex = re.compile(r'((\-|\/)I.*)')
-                include_list = [
-                    m.group(1)
-                    for m in (include_regex.match(elem) for elem in cmd) if m
-                ]
-
-                if len(src_list) >= 1 and len(obj_list) >= 1:
-                    src = src_list[0]
-                    obj = obj_list[0]
-                    if _is_cuda_file(src):
-                        nvcc = _join_cuda_home('bin', 'nvcc')
-                        if isinstance(self.cflags, dict):
-                            cflags = self.cflags['nvcc']
-                        elif isinstance(self.cflags, list):
-                            cflags = self.cflags
-                        else:
-                            cflags = []
-
-                        cflags = win_cuda_flags(cflags) + ['--use-local-env']
-                        for flag in COMMON_MSVC_FLAGS:
-                            cflags = ['-Xcompiler', flag] + cflags
-                        for ignore_warning in MSVC_IGNORE_CUDAFE_WARNINGS:
-                            cflags = ['-Xcudafe', '--diag_suppress=' + ignore_warning] + cflags
-                        cmd = [nvcc, '-c', src, '-o', obj] + include_list + cflags
-                    elif isinstance(self.cflags, dict):
-                        cflags = COMMON_MSVC_FLAGS + self.cflags['cxx']
-                        cmd += cflags
-                    elif isinstance(self.cflags, list):
-                        cflags = COMMON_MSVC_FLAGS + self.cflags
-                        cmd += cflags
-
-                return original_spawn(cmd)
-
-            try:
-                self.compiler.spawn = spawn
-                return original_compile(sources, output_dir, macros,
-                                        include_dirs, debug, extra_preargs,
-                                        extra_postargs, depends)
-            finally:
-                self.compiler.spawn = original_spawn
-
-        def win_wrap_ninja_compile(sources,
-                                   output_dir=None,
-                                   macros=None,
-                                   include_dirs=None,
-                                   debug=0,
-                                   extra_preargs=None,
-                                   extra_postargs=None,
-                                   depends=None):
-
-            if not self.compiler.initialized:
-                self.compiler.initialize()
-            output_dir = os.path.abspath(output_dir)
-
-            # Note [Absolute include_dirs]
-            # Convert relative path in self.compiler.include_dirs to absolute path if any,
-            # For ninja build, the build location is not local, the build happens
-            # in a in script created build folder, relative path lost their correctness.
-            # To be consistent with jit extension, we allow user to enter relative include_dirs
-            # in setuptools.setup, and we convert the relative path to absolute path here
-            convert_to_absolute_paths_inplace(self.compiler.include_dirs)
-
-            _, objects, extra_postargs, pp_opts, _ = \
-                self.compiler._setup_compile(output_dir, macros,
-                                             include_dirs, sources,
-                                             depends, extra_postargs)
-            common_cflags = extra_preargs or []
-            cflags = []
-            if debug:
-                cflags.extend(self.compiler.compile_options_debug)
-            else:
-                cflags.extend(self.compiler.compile_options)
-            common_cflags.extend(COMMON_MSVC_FLAGS)
-            cflags = cflags + common_cflags + pp_opts
-            with_cuda = any(map(_is_cuda_file, sources))
-
-            # extra_postargs can be either:
-            # - a dict mapping cxx/nvcc to extra flags
-            # - a list of extra flags.
-            if isinstance(extra_postargs, dict):
-                post_cflags = extra_postargs['cxx']
-            else:
-                post_cflags = list(extra_postargs)
-            append_std14_if_no_std_present(post_cflags)
-
-            cuda_post_cflags = None
-            cuda_cflags = None
-            if with_cuda:
-                cuda_cflags = ['--use-local-env']
-                for common_cflag in common_cflags:
-                    cuda_cflags.append('-Xcompiler')
-                    cuda_cflags.append(common_cflag)
-                for ignore_warning in MSVC_IGNORE_CUDAFE_WARNINGS:
-                    cuda_cflags.append('-Xcudafe')
-                    cuda_cflags.append('--diag_suppress=' + ignore_warning)
-                cuda_cflags.extend(pp_opts)
-                if isinstance(extra_postargs, dict):
-                    cuda_post_cflags = extra_postargs['nvcc']
-                else:
-                    cuda_post_cflags = list(extra_postargs)
-                cuda_post_cflags = win_cuda_flags(cuda_post_cflags)
-
-            cflags = _nt_quote_args(cflags)
-            post_cflags = _nt_quote_args(post_cflags)
-            if with_cuda:
-                cuda_cflags = _nt_quote_args(cuda_cflags)
-                cuda_post_cflags = _nt_quote_args(cuda_post_cflags)
-
-            _write_ninja_file_and_compile_objects(
-                sources=sources,
-                objects=objects,
-                cflags=cflags,
-                post_cflags=post_cflags,
-                cuda_cflags=cuda_cflags,
-                cuda_post_cflags=cuda_post_cflags,
-                build_directory=output_dir,
-                verbose=True,
-                with_cuda=with_cuda)
-
-            # Return *all* object filenames, not just the ones we just built.
-            return objects
-
         # Monkey-patch the _compile or compile method.
         # https://github.com/python/cpython/blob/dc0284ee8f7a270b6005467f26d8e5773d76e959/Lib/distutils/ccompiler.py#L511
-        if self.compiler.compiler_type == 'msvc':
-            if self.use_ninja:
-                self.compiler.compile = win_wrap_ninja_compile
-            else:
-                self.compiler.compile = win_wrap_single_compile
+
+        if self.use_ninja:
+            self.compiler.compile = unix_wrap_ninja_compile
         else:
-            if self.use_ninja:
-                self.compiler.compile = unix_wrap_ninja_compile
-            else:
-                self.compiler._compile = unix_wrap_single_compile
+            self.compiler._compile = unix_wrap_single_compile
 
         build_ext.build_extensions(self)
 
@@ -1135,24 +821,6 @@ class BuildExtension(build_ext, object):
             compiler = os.environ.get('CXX', 'c++')
         check_compiler_abi_compatibility(compiler)
 
-    # def _check_cuda_version(self):
-    #     if CUDA_HOME:
-    #         nvcc = os.path.join(CUDA_HOME, 'bin', 'nvcc')
-    #         cuda_version_str = subprocess.check_output([nvcc, '--version']).strip().decode(*SUBPROCESS_DECODE_ARGS)
-    #         cuda_version = re.search(r'release (\d+[.]\d+)', cuda_version_str)
-    #         if cuda_version is not None:
-    #             cuda_str_version = cuda_version.group(1)
-    #             cuda_ver = packaging.version.parse(cuda_str_version)
-    #             torch_cuda_version = packaging.version.parse(torch.version.cuda)
-    #             if cuda_ver != torch_cuda_version:
-    #                 # major/minor attributes are only available in setuptools>=49.6.0
-    #                 if getattr(cuda_ver, "major", float("nan")) != getattr(torch_cuda_version, "major", float("nan")):
-    #                     raise RuntimeError(CUDA_MISMATCH_MESSAGE.format(cuda_str_version, torch.version.cuda))
-    #                 warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))
-
-    #     else:
-    #         raise RuntimeError(CUDA_NOT_FOUND_MESSAGE)
-
     def _add_compile_flag(self, extension, flag):
         extension.extra_compile_args = copy.deepcopy(extension.extra_compile_args)
         if isinstance(extension.extra_compile_args, dict):
@@ -1162,10 +830,6 @@ class BuildExtension(build_ext, object):
             extension.extra_compile_args.append(flag)
 
     def _define_torch_extension_name(self, extension):
-        # pybind11 doesn't support dots in the names
-        # so in order to support extensions in the packages
-        # like torch._C, we take the last part of the string
-        # as the library name
         names = extension.name.split('.')
         name = names[-1]
         define = f'-DTORCH_EXTENSION_NAME={name}'
@@ -1176,7 +840,6 @@ class BuildExtension(build_ext, object):
         self._add_compile_flag(extension, '-D_GLIBCXX_USE_CXX11_ABI=' + str(int(True)))
 
 
-
 if __name__ == "__main__":
     print("Building wheel {}-{}".format(package_name, version))
 
@@ -1209,7 +872,6 @@ if __name__ == "__main__":
         ext_modules=get_extensions(),
         cmdclass={
             'build_ext': BuildExtension,
-            # .with_options(no_python_abi_suffix=True),
             'clean': clean,
         }
     )
-- 
2.25.1

