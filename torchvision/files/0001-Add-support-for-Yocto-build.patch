From a0b25e1606210bb075b3848cd073338ec3d6a5d9 Mon Sep 17 00:00:00 2001
From: t-kuha <imagingtechnerd@gmail.com>
Date: Sat, 26 Feb 2022 13:59:44 +0900
Subject: [PATCH] Add support for Yocto

---
 setup.py | 641 +++++++++++++++++++++++++++++++++++++++++++------------
 1 file changed, 504 insertions(+), 137 deletions(-)

diff --git a/setup.py b/setup.py
index 4c9e734f3..6cc780bb0 100644
--- a/setup.py
+++ b/setup.py
@@ -2,17 +2,18 @@ import os
 import io
 import re
 import sys
-from setuptools import setup, find_packages
-from pkg_resources import parse_version, get_distribution, DistributionNotFound
+from setuptools import setup, find_packages, Extension
+from setuptools.command.build_ext import build_ext
+from pkg_resources import get_distribution, DistributionNotFound
 import subprocess
 import distutils.command.clean
 import distutils.spawn
-from distutils.version import StrictVersion
 import glob
 import shutil
-
-import torch
-from torch.utils.cpp_extension import BuildExtension, CppExtension, CUDAExtension, CUDA_HOME
+from typing import List
+import copy
+import shlex
+import warnings
 
 
 def read(*names, **kwargs):
@@ -74,6 +75,48 @@ pillow_req = 'pillow-simd' if get_dist('pillow-simd') is not None else 'pillow'
 requirements.append(pillow_req + pillow_ver)
 
 
+_TORCH_PATH = os.path.join(
+    os.environ.get('PKG_CONFIG_SYSROOT_DIR', None),
+    'usr', 'lib', f'python{sys.version_info.major}.{sys.version_info.minor}', 'site-packages', 'torch')
+
+
+def include_paths(cuda=False):
+    lib_include = os.path.join(_TORCH_PATH, 'include')
+    paths = [
+        lib_include,
+        # Remove this once torch/torch.h is officially no longer supported for C++ extensions.
+        os.path.join(lib_include, 'torch', 'csrc', 'api', 'include'),
+        os.path.join(os.environ.get('PKG_CONFIG_SYSROOT_DIR', None), 'usr', 'include', f'python{sys.version_info.major}.{sys.version_info.minor}')
+    ]
+    return paths
+
+
+def library_paths(cuda=False):
+    paths = [os.path.join(_TORCH_PATH, 'lib')]
+    return paths
+
+
+def CppExtension(name, sources, *args, **kwargs):
+    include_dirs = kwargs.get('include_dirs', [])
+    include_dirs += include_paths()
+
+    kwargs['include_dirs'] = include_dirs
+
+    library_dirs = kwargs.get('library_dirs', [])
+    library_dirs += library_paths()
+    kwargs['library_dirs'] = library_dirs
+
+    libraries = kwargs.get('libraries', [])
+    libraries.append('c10')
+    libraries.append('torch')
+    libraries.append('torch_cpu')
+    libraries.append('torch_python')
+    kwargs['libraries'] = libraries
+
+    kwargs['language'] = 'c++'
+    return Extension(name, sources, *args, **kwargs)
+
+
 def find_library(name, vision_include):
     this_dir = os.path.dirname(os.path.abspath(__file__))
     build_prefix = os.environ.get('BUILD_PREFIX', None)
@@ -146,32 +189,6 @@ def get_extensions():
         glob.glob(os.path.join(extensions_dir, 'ops', 'quantized', 'cpu', '*.cpp'))
     )
 
-    is_rocm_pytorch = False
-    TORCH_MAJOR = int(torch.__version__.split('.')[0])
-    TORCH_MINOR = int(torch.__version__.split('.')[1])
-    if TORCH_MAJOR > 1 or (TORCH_MAJOR == 1 and TORCH_MINOR >= 5):
-        from torch.utils.cpp_extension import ROCM_HOME
-        is_rocm_pytorch = True if ((torch.version.hip is not None) and (ROCM_HOME is not None)) else False
-
-    if is_rocm_pytorch:
-        from torch.utils.hipify import hipify_python
-        hipify_python.hipify(
-            project_directory=this_dir,
-            output_directory=this_dir,
-            includes="torchvision/csrc/ops/cuda/*",
-            show_detailed=True,
-            is_pytorch_extension=True,
-        )
-        source_cuda = glob.glob(os.path.join(extensions_dir, 'ops', 'hip', '*.hip'))
-        # Copy over additional files
-        for file in glob.glob(r"torchvision/csrc/ops/cuda/*.h"):
-            shutil.copy(file, "torchvision/csrc/ops/hip")
-
-    else:
-        source_cuda = glob.glob(os.path.join(extensions_dir, 'ops', 'cuda', '*.cu'))
-
-    source_cuda += glob.glob(os.path.join(extensions_dir, 'ops', 'autocast', '*.cpp'))
-
     sources = main_file + source_cpu
     extension = CppExtension
 
@@ -190,26 +207,6 @@ def get_extensions():
     define_macros = []
 
     extra_compile_args = {'cxx': []}
-    if (torch.cuda.is_available() and ((CUDA_HOME is not None) or is_rocm_pytorch)) \
-            or os.getenv('FORCE_CUDA', '0') == '1':
-        extension = CUDAExtension
-        sources += source_cuda
-        if not is_rocm_pytorch:
-            define_macros += [('WITH_CUDA', None)]
-            nvcc_flags = os.getenv('NVCC_FLAGS', '')
-            if nvcc_flags == '':
-                nvcc_flags = []
-            else:
-                nvcc_flags = nvcc_flags.split(' ')
-        else:
-            define_macros += [('WITH_HIP', None)]
-            nvcc_flags = []
-        extra_compile_args["nvcc"] = nvcc_flags
-
-    if sys.platform == 'win32':
-        define_macros += [('torchvision_EXPORTS', None)]
-
-        extra_compile_args['cxx'].append('/MP')
 
     debug_mode = os.getenv('DEBUG', '0') == '1'
     if debug_mode:
@@ -259,6 +256,8 @@ def get_extensions():
     include_dirs += vision_include
     library_dirs = vision_library
 
+    library_dirs += [os.path.join(_TORCH_PATH, 'lib')]
+
     # Image reading extension
     image_macros = []
     image_include = [extensions_dir]
@@ -266,49 +265,18 @@ def get_extensions():
     image_link_flags = []
 
     # Locating libPNG
-    libpng = distutils.spawn.find_executable('libpng-config')
-    pngfix = distutils.spawn.find_executable('pngfix')
-    png_found = libpng is not None or pngfix is not None
+    png_found = True  # libpng is not None or pngfix is not None
+    # png_include = os.path.join(os.environ['PKG_CONFIG_SYSROOT_DIR'], 'usr', 'include')
+    # png_lib = os.path.join(os.environ['PKG_CONFIG_SYSROOT_DIR'], 'usr', 'lib')
     print('PNG found: {0}'.format(png_found))
-    if png_found:
-        if libpng is not None:
-            # Linux / Mac
-            png_version = subprocess.run([libpng, '--version'],
-                                         stdout=subprocess.PIPE)
-            png_version = png_version.stdout.strip().decode('utf-8')
-            print('libpng version: {0}'.format(png_version))
-            png_version = parse_version(png_version)
-            if png_version >= parse_version("1.6.0"):
-                print('Building torchvision with PNG image support')
-                png_lib = subprocess.run([libpng, '--libdir'],
-                                         stdout=subprocess.PIPE)
-                png_lib = png_lib.stdout.strip().decode('utf-8')
-                if 'disabled' not in png_lib:
-                    image_library += [png_lib]
-                png_include = subprocess.run([libpng, '--I_opts'],
-                                             stdout=subprocess.PIPE)
-                png_include = png_include.stdout.strip().decode('utf-8')
-                _, png_include = png_include.split('-I')
-                print('libpng include path: {0}'.format(png_include))
-                image_include += [png_include]
-                image_link_flags.append('png')
-            else:
-                print('libpng installed version is less than 1.6.0, '
-                      'disabling PNG support')
-                png_found = False
-        else:
-            # Windows
-            png_lib = os.path.join(
-                os.path.dirname(os.path.dirname(pngfix)), 'lib')
-            png_include = os.path.join(os.path.dirname(
-                os.path.dirname(pngfix)), 'include', 'libpng16')
-            image_library += [png_lib]
-            image_include += [png_include]
-            image_link_flags.append('libpng')
+    image_link_flags.append('png')
 
     # Locating libjpeg
-    (jpeg_found, jpeg_conda,
-     jpeg_include, jpeg_lib) = find_library('jpeglib', vision_include)
+    jpeg_found = True
+    jpeg_conda = False
+    jpeg_include = os.path.join(os.environ['PKG_CONFIG_SYSROOT_DIR'], 'usr', 'include')
+    jpeg_lib = os.path.join(os.environ['PKG_CONFIG_SYSROOT_DIR'], 'usr', 'lib')
+    image_link_flags.append('jpeg')
 
     print('JPEG found: {0}'.format(jpeg_found))
     image_macros += [('PNG_FOUND', str(int(png_found)))]
@@ -322,11 +290,7 @@ def get_extensions():
 
     # Locating nvjpeg
     # Should be included in CUDA_HOME for CUDA >= 10.1, which is the minimum version we have in the CI
-    nvjpeg_found = (
-        extension is CUDAExtension and
-        CUDA_HOME is not None and
-        os.path.exists(os.path.join(CUDA_HOME, 'include', 'nvjpeg.h'))
-    )
+    nvjpeg_found = False
 
     print('NVJPEG found: {0}'.format(nvjpeg_found))
     image_macros += [('NVJPEG_FOUND', str(int(nvjpeg_found)))]
@@ -349,22 +313,7 @@ def get_extensions():
             extra_compile_args=extra_compile_args
         ))
 
-    ffmpeg_exe = distutils.spawn.find_executable('ffmpeg')
-    has_ffmpeg = ffmpeg_exe is not None
-    # FIXME: Building torchvision with ffmpeg on MacOS or with Python 3.9
-    # FIXME: causes crash. See the following GitHub issues for more details.
-    # FIXME: https://github.com/pytorch/pytorch/issues/65000
-    # FIXME: https://github.com/pytorch/vision/issues/3367
-    if sys.platform != 'linux' or (
-            sys.version_info.major == 3 and sys.version_info.minor == 9):
-        has_ffmpeg = False
-    if has_ffmpeg:
-        try:
-            # This is to check if ffmpeg is installed properly.
-            subprocess.check_output(["ffmpeg", "-version"])
-        except subprocess.CalledProcessError:
-            print('Error fetching ffmpeg version, ignoring ffmpeg.')
-            has_ffmpeg = False
+    has_ffmpeg = True
 
     print("FFmpeg found: {}".format(has_ffmpeg))
 
@@ -377,29 +326,8 @@ def get_extensions():
             'libswscale'
         }
 
-        ffmpeg_bin = os.path.dirname(ffmpeg_exe)
-        ffmpeg_root = os.path.dirname(ffmpeg_bin)
-        ffmpeg_include_dir = os.path.join(ffmpeg_root, 'include')
-        ffmpeg_library_dir = os.path.join(ffmpeg_root, 'lib')
-
-        gcc = distutils.spawn.find_executable('gcc')
-        platform_tag = subprocess.run(
-            [gcc, '-print-multiarch'], stdout=subprocess.PIPE)
-        platform_tag = platform_tag.stdout.strip().decode('utf-8')
-
-        if platform_tag:
-            # Most probably a Debian-based distribution
-            ffmpeg_include_dir = [
-                ffmpeg_include_dir,
-                os.path.join(ffmpeg_include_dir, platform_tag)
-            ]
-            ffmpeg_library_dir = [
-                ffmpeg_library_dir,
-                os.path.join(ffmpeg_library_dir, platform_tag)
-            ]
-        else:
-            ffmpeg_include_dir = [ffmpeg_include_dir]
-            ffmpeg_library_dir = [ffmpeg_library_dir]
+        ffmpeg_include_dir = [jpeg_include]
+        ffmpeg_library_dir = [jpeg_lib]
 
         has_ffmpeg = True
         for library in ffmpeg_libraries:
@@ -473,6 +401,445 @@ class clean(distutils.command.clean.clean):
         distutils.command.clean.clean.run(self)
 
 
+SUBPROCESS_DECODE_ARGS = ()
+MINIMUM_GCC_VERSION = (5, 0, 0)
+
+
+def is_ninja_available():
+    try:
+        subprocess.check_output('ninja --version'.split())
+    except Exception:
+        return False
+    else:
+        return True
+
+
+def _get_num_workers(verbose: bool):
+    max_jobs = os.environ.get('MAX_JOBS')
+    if max_jobs is not None and max_jobs.isdigit():
+        if verbose:
+            print(f'Using envvar MAX_JOBS ({max_jobs}) as the number of workers...')
+        return int(max_jobs)
+    if verbose:
+        print('Allowing ninja to set a default number of workers... '
+              '(overridable by setting the environment variable MAX_JOBS=N)')
+    return None
+
+
+def _is_cuda_file(path: str) -> bool:
+    valid_ext = ['.cu', '.cuh']
+    return os.path.splitext(path)[1] in valid_ext
+
+
+def verify_ninja_availability():
+    if not is_ninja_available():
+        raise RuntimeError("Ninja is required to load C++ extensions")
+
+
+def _write_ninja_file(path,
+                      cflags,
+                      post_cflags,
+                      cuda_cflags,
+                      cuda_post_cflags,
+                      sources,
+                      objects,
+                      ldflags,
+                      library_target,
+                      with_cuda) -> None:
+    def sanitize_flags(flags):
+        if flags is None:
+            return []
+        else:
+            return [flag.strip() for flag in flags]
+
+    cflags = sanitize_flags(cflags)
+    post_cflags = sanitize_flags(post_cflags)
+    cuda_cflags = sanitize_flags(cuda_cflags)
+    cuda_post_cflags = sanitize_flags(cuda_post_cflags)
+    ldflags = sanitize_flags(ldflags)
+
+    # Sanity checks...
+    assert len(sources) == len(objects)
+    assert len(sources) > 0
+
+    compiler = os.environ.get('CXX', 'c++')
+
+    # Version 1.3 is required for the `deps` directive.
+    config = ['ninja_required_version = 1.3']
+    config.append(f'cxx = {compiler}')
+
+    flags = [f'cflags = {" ".join(cflags)}']
+    flags.append(f'post_cflags = {" ".join(post_cflags)}')
+    flags.append(f'ldflags = {" ".join(ldflags)}')
+
+    # Turn into absolute paths so we can emit them into the ninja build
+    # file wherever it is.
+    sources = [os.path.abspath(file) for file in sources]
+
+    # See https://ninja-build.org/build.ninja.html for reference.
+    compile_rule = ['rule compile']
+    compile_rule.append(
+        '  command = $cxx -MMD -MF $out.d $cflags -c $in -o $out $post_cflags')
+    compile_rule.append('  depfile = $out.d')
+    compile_rule.append('  deps = gcc')
+
+    # Emit one build rule per source to enable incremental build.
+    build = []
+    for source_file, object_file in zip(sources, objects):
+        is_cuda_source = _is_cuda_file(source_file) and with_cuda
+        rule = 'cuda_compile' if is_cuda_source else 'compile'
+        source_file = source_file.replace(" ", "$ ")
+        object_file = object_file.replace(" ", "$ ")
+        build.append(f'build {object_file}: {rule} {source_file}')
+
+    if library_target is not None:
+        link_rule = ['rule link']
+        link_rule.append('  command = $cxx $in $ldflags -o $out')
+
+        link = [f'build {library_target}: link {" ".join(objects)}']
+
+        default = [f'default {library_target}']
+    else:
+        link_rule, link, default = [], [], []
+
+    # 'Blocks' should be separated by newlines, for visual benefit.
+    blocks = [config, flags, compile_rule]
+    blocks += [link_rule, build, link, default]
+    with open(path, 'w') as build_file:
+        for block in blocks:
+            lines = '\n'.join(block)
+            build_file.write(f'{lines}\n\n')
+
+
+def _write_ninja_file_and_compile_objects(
+        sources: List[str],
+        objects,
+        cflags,
+        post_cflags,
+        cuda_cflags,
+        cuda_post_cflags,
+        build_directory: str,
+        verbose: bool,
+        with_cuda) -> None:
+    verify_ninja_availability()
+    compiler = os.environ.get('CXX', 'c++')
+    check_compiler_abi_compatibility(compiler)
+    if with_cuda is None:
+        with_cuda = any(map(_is_cuda_file, sources))
+    build_file_path = os.path.join(build_directory, 'build.ninja')
+    if verbose:
+        print(f'Emitting ninja build file {build_file_path}...')
+    _write_ninja_file(
+        path=build_file_path,
+        cflags=cflags,
+        post_cflags=post_cflags,
+        cuda_cflags=cuda_cflags,
+        cuda_post_cflags=cuda_post_cflags,
+        sources=sources,
+        objects=objects,
+        ldflags=[os.environ['LDFLAGS'], '-L' + os.path.join(os.environ['PKG_CONFIG_SYSROOT_DIR'], 'usr', 'lib')],
+        library_target=None,
+        with_cuda=with_cuda)
+    if verbose:
+        print('Compiling objects...')
+    _run_ninja_build(
+        build_directory,
+        verbose,
+        # It would be better if we could tell users the name of the extension
+        # that failed to build but there isn't a good way to get it here.
+        error_prefix='Error compiling objects for extension')
+
+
+def _run_ninja_build(build_directory: str, verbose: bool, error_prefix: str) -> None:
+    command = ['ninja', '-v']
+    num_workers = _get_num_workers(verbose)
+    if num_workers is not None:
+        command.extend(['-j', str(num_workers)])
+    env = os.environ.copy()
+    try:
+        sys.stdout.flush()
+        sys.stderr.flush()
+        stdout_fileno = 1
+        subprocess.run(
+            command,
+            stdout=stdout_fileno if verbose else subprocess.PIPE,
+            stderr=subprocess.STDOUT,
+            cwd=build_directory,
+            check=True,
+            env=env)
+    except subprocess.CalledProcessError as e:
+        # Python 2 and 3 compatible way of getting the error object.
+        _, error, _ = sys.exc_info()
+        # error.output contains the stdout and stderr of the build attempt.
+        message = error_prefix
+        # `error` is a CalledProcessError (which has an `ouput`) attribute, but
+        # mypy thinks it's Optional[BaseException] and doesn't narrow
+        if hasattr(error, 'output') and error.output:  # type: ignore[union-attr]
+            message += f": {error.output.decode(*SUBPROCESS_DECODE_ARGS)}"  # type: ignore[union-attr]
+        raise RuntimeError(message) from e
+
+
+def _accepted_compilers_for_platform() -> List[str]:
+    # gnu-c++ and gnu-cc are the conda gcc compilers
+    return ['clang++', 'clang'] if sys.platform.startswith('darwin') else ['g++', 'gcc', 'gnu-c++', 'gnu-cc']
+
+
+def check_compiler_abi_compatibility(compiler) -> bool:
+    if os.environ.get('TORCH_DONT_CHECK_COMPILER_ABI') in ['ON', '1', 'YES', 'TRUE', 'Y']:
+        return True
+
+    # First check if the compiler is one of the expected ones for the particular platform.
+    if not check_compiler_ok_for_platform(compiler):
+        warnings.warn(f'Your compiler ({compiler}) is not compatible with the compiler Pytorch was built with for this platform')
+        return False
+
+    if sys.platform.startswith('darwin'):
+        # There is no particular minimum version we need for clang, so we're good here.
+        return True
+    try:
+        if sys.platform.startswith('linux'):
+            minimum_required_version = MINIMUM_GCC_VERSION
+            versionstr = subprocess.check_output([compiler.split(' ')[0], '-dumpfullversion', '-dumpversion'])
+            version = versionstr.decode(*SUBPROCESS_DECODE_ARGS).strip().split('.')
+    except Exception:
+        _, error, _ = sys.exc_info()
+        warnings.warn(f'Error checking compiler version for {compiler}: {error}')
+        return False
+
+    if tuple(map(int, version)) >= minimum_required_version:
+        return True
+
+    compiler = f'{compiler} {".".join(version)}'
+    warnings.warn(f'Your compiler ({compiler}) may be ABI-incompatible with PyTorch!')
+
+    return False
+
+
+def check_compiler_ok_for_platform(compiler: str) -> bool:
+    which = subprocess.check_output(['which', compiler.split(' ')[0]], stderr=subprocess.STDOUT)
+    # Use os.path.realpath to resolve any symlinks, in particular from 'c++' to e.g. 'g++'.
+    compiler_path = os.path.realpath(which.decode(*SUBPROCESS_DECODE_ARGS).strip())
+    # Check the compiler name
+    if any(name in compiler_path for name in _accepted_compilers_for_platform()):
+        return True
+    # If ccache is used the compiler path is /usr/bin/ccache. Check by -v flag.
+    version_string = subprocess.check_output([compiler, '-v'], stderr=subprocess.STDOUT).decode(*SUBPROCESS_DECODE_ARGS)
+    if sys.platform.startswith('linux'):
+        # Check for 'gcc' or 'g++'
+        pattern = re.compile("^COLLECT_GCC=(.*)$", re.MULTILINE)
+        results = re.findall(pattern, version_string)
+        if len(results) != 1:
+            return False
+        compiler_path = os.path.realpath(results[0].strip())
+        return any(name in compiler_path for name in _accepted_compilers_for_platform())
+    if sys.platform.startswith('darwin'):
+        # Check for 'clang' or 'clang++'
+        return version_string.startswith("Apple clang")
+    return False
+
+
+class BuildExtension(build_ext, object):
+    @classmethod
+    def with_options(cls, **options):
+        r'''
+        Returns a subclass with alternative constructor that extends any original keyword
+        arguments to the original constructor with the given options.
+        '''
+        class cls_with_options(cls):  # type: ignore[misc, valid-type]
+            def __init__(self, *args, **kwargs):
+                kwargs.update(options)
+                super().__init__(*args, **kwargs)
+
+        return cls_with_options
+
+    def __init__(self, *args, **kwargs) -> None:
+        super(BuildExtension, self).__init__(*args, **kwargs)
+        self.no_python_abi_suffix = kwargs.get("no_python_abi_suffix", False)
+
+        self.use_ninja = kwargs.get('use_ninja', True)
+        if self.use_ninja:
+            # Test if we can use ninja. Fallback otherwise.
+            msg = ('Attempted to use ninja as the BuildExtension backend but '
+                   '{}. Falling back to using the slow distutils backend.')
+            if not is_ninja_available():
+                warnings.warn(msg.format('we could not find ninja.'))
+                self.use_ninja = False
+
+    def finalize_options(self) -> None:
+        super().finalize_options()
+        if self.use_ninja:
+            self.force = True
+
+    def build_extensions(self) -> None:
+        self._check_abi()
+
+        cuda_ext = False
+        extension_iter = iter(self.extensions)
+        extension = next(extension_iter, None)
+        while not cuda_ext and extension:
+            for source in extension.sources:
+                _, ext = os.path.splitext(source)
+                if ext == '.cu':
+                    cuda_ext = True
+                    break
+            extension = next(extension_iter, None)
+
+        for extension in self.extensions:
+            if isinstance(extension.extra_compile_args, dict):
+                for ext in ['cxx', 'nvcc']:
+                    if ext not in extension.extra_compile_args:
+                        extension.extra_compile_args[ext] = []
+
+            self._add_compile_flag(extension, '-DTORCH_API_INCLUDE_EXTENSION_H')
+            # See note [Pybind11 ABI constants]
+            for name, val in {"COMPILER_TYPE": '_gcc', "STDLIB": '_libstdcpp', "BUILD_ABI": '_cxxabi1014'}.items():
+                self._add_compile_flag(extension, f'-DPYBIND11_{name}="{val}"')
+            self._define_torch_extension_name(extension)
+            self._add_gnu_cpp_abi_flag(extension)
+
+        # Register .cu, .cuh and .hip as valid source extensions.
+        self.compiler.src_extensions += ['.cu', '.cuh', '.hip']
+        # Save the original _compile method for later.
+        if self.compiler.compiler_type == 'msvc':
+            self.compiler._cpp_extensions += ['.cu', '.cuh']
+            original_compile = self.compiler.compile
+        else:
+            original_compile = self.compiler._compile
+
+        def append_std14_if_no_std_present(cflags) -> None:
+            # NVCC does not allow multiple -std to be passed, so we avoid
+            # overriding the option if the user explicitly passed it.
+            cpp_format_prefix = '/{}:' if self.compiler.compiler_type == 'msvc' else '-{}='
+            cpp_flag_prefix = cpp_format_prefix.format('std')
+            cpp_flag = cpp_flag_prefix + 'c++14'
+            if not any(flag.startswith(cpp_flag_prefix) for flag in cflags):
+                cflags.append(cpp_flag)
+
+        def convert_to_absolute_paths_inplace(paths):
+            # Helper function. See Note [Absolute include_dirs]
+            if paths is not None:
+                for i in range(len(paths)):
+                    if not os.path.isabs(paths[i]):
+                        paths[i] = os.path.abspath(paths[i])
+
+        def unix_wrap_single_compile(obj, src, ext, cc_args, extra_postargs, pp_opts) -> None:
+            # Copy before we make any modifications.
+            cflags = copy.deepcopy(extra_postargs)
+            try:
+                original_compiler = self.compiler.compiler_so
+                if _is_cuda_file(src):
+                    pass
+                elif isinstance(cflags, dict):
+                    cflags = cflags['cxx']
+                append_std14_if_no_std_present(cflags)
+
+                original_compile(obj, src, ext, cc_args, cflags, pp_opts)
+            finally:
+                # Put the original compiler back in place.
+                self.compiler.set_executable('compiler_so', original_compiler)
+
+        def unix_wrap_ninja_compile(sources,
+                                    output_dir=None,
+                                    macros=None,
+                                    include_dirs=None,
+                                    debug=0,
+                                    extra_preargs=None,
+                                    extra_postargs=None,
+                                    depends=None):
+            output_dir = os.path.abspath(output_dir)
+
+            # See Note [Absolute include_dirs]
+            convert_to_absolute_paths_inplace(self.compiler.include_dirs)
+
+            _, objects, extra_postargs, pp_opts, _ = \
+                self.compiler._setup_compile(output_dir, macros,
+                                             include_dirs, sources,
+                                             depends, extra_postargs)
+            common_cflags = self.compiler._get_cc_args(pp_opts, debug, extra_preargs)
+            extra_cc_cflags = self.compiler.compiler_so[1:]
+            with_cuda = any(map(_is_cuda_file, sources))
+
+            # extra_postargs can be either:
+            # - a dict mapping cxx/nvcc to extra flags
+            # - a list of extra flags.
+            if isinstance(extra_postargs, dict):
+                post_cflags = extra_postargs['cxx']
+            else:
+                post_cflags = list(extra_postargs)
+            # if IS_HIP_EXTENSION:
+            #     post_cflags = COMMON_HIP_FLAGS + post_cflags
+            append_std14_if_no_std_present(post_cflags)
+
+            cuda_post_cflags = None
+            cuda_cflags = None
+
+            _write_ninja_file_and_compile_objects(
+                sources=sources,
+                objects=objects,
+                cflags=[shlex.quote(f) for f in extra_cc_cflags + common_cflags],
+                post_cflags=[shlex.quote(f) for f in post_cflags],
+                cuda_cflags=cuda_cflags,
+                cuda_post_cflags=cuda_post_cflags,
+                build_directory=output_dir,
+                verbose=True,
+                with_cuda=with_cuda)
+
+            # Return *all* object filenames, not just the ones we just built.
+            return objects
+
+        # Monkey-patch the _compile or compile method.
+        # https://github.com/python/cpython/blob/dc0284ee8f7a270b6005467f26d8e5773d76e959/Lib/distutils/ccompiler.py#L511
+
+        if self.use_ninja:
+            self.compiler.compile = unix_wrap_ninja_compile
+        else:
+            self.compiler._compile = unix_wrap_single_compile
+
+        build_ext.build_extensions(self)
+
+    def get_ext_filename(self, ext_name):
+        # Get the original shared library name. For Python 3, this name will be
+        # suffixed with "<SOABI>.so", where <SOABI> will be something like
+        # cpython-37m-x86_64-linux-gnu.
+        ext_filename = super(BuildExtension, self).get_ext_filename(ext_name)
+        # If `no_python_abi_suffix` is `True`, we omit the Python 3 ABI
+        # component. This makes building shared libraries with setuptools that
+        # aren't Python modules nicer.
+        if self.no_python_abi_suffix:
+            # The parts will be e.g. ["my_extension", "cpython-37m-x86_64-linux-gnu", "so"].
+            ext_filename_parts = ext_filename.split('.')
+            # Omit the second to last element.
+            without_abi = ext_filename_parts[:-2] + ext_filename_parts[-1:]
+            ext_filename = '.'.join(without_abi)
+        return ext_filename
+
+    def _check_abi(self):
+        # On some platforms, like Windows, compiler_cxx is not available.
+        if hasattr(self.compiler, 'compiler_cxx'):
+            compiler = self.compiler.compiler_cxx[0]
+        else:
+            compiler = os.environ.get('CXX', 'c++')
+        check_compiler_abi_compatibility(compiler)
+
+    def _add_compile_flag(self, extension, flag):
+        extension.extra_compile_args = copy.deepcopy(extension.extra_compile_args)
+        if isinstance(extension.extra_compile_args, dict):
+            for args in extension.extra_compile_args.values():
+                args.append(flag)
+        else:
+            extension.extra_compile_args.append(flag)
+
+    def _define_torch_extension_name(self, extension):
+        names = extension.name.split('.')
+        name = names[-1]
+        define = f'-DTORCH_EXTENSION_NAME={name}'
+        self._add_compile_flag(extension, define)
+
+    def _add_gnu_cpp_abi_flag(self, extension):
+        # use the same CXX ABI as what PyTorch was compiled with
+        self._add_compile_flag(extension, '-D_GLIBCXX_USE_CXX11_ABI=' + str(int(True)))
+
+
 if __name__ == "__main__":
     print("Building wheel {}-{}".format(package_name, version))
 
@@ -504,7 +871,7 @@ if __name__ == "__main__":
         },
         ext_modules=get_extensions(),
         cmdclass={
-            'build_ext': BuildExtension.with_options(no_python_abi_suffix=True),
+            'build_ext': BuildExtension,
             'clean': clean,
         }
     )
-- 
2.25.1

